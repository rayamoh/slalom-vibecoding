{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7599cef9",
   "metadata": {},
   "source": [
    "# Dataset Exploration and Validation\n",
    "## PaySim Synthetic Financial Fraud Detection Dataset\n",
    "\n",
    "**Objective**: Validate dataset structure, understand distributions, and verify alignment with PRD constraints.\n",
    "\n",
    "**Key Constraints**:\n",
    "- ‚ùå Cannot use balance columns (oldbalanceOrg, newbalanceOrig, oldbalanceDest, newbalanceDest)\n",
    "- ‚úÖ Available features: step, type, amount, nameOrig, nameDest\n",
    "- ‚úÖ Target: isFraud\n",
    "- ‚úÖ Rule indicator: isFlaggedFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c91786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f6c47",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_path = Path('../dataset/Synthetic_Financial_datasets_log.csv')\n",
    "print(f\"Loading dataset from: {dataset_path}\")\n",
    "print(f\"File exists: {dataset_path.exists()}\")\n",
    "print(f\"File size: {dataset_path.stat().st_size / (1024**2):.2f} MB\\n\")\n",
    "\n",
    "# Read CSV\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully\")\n",
    "print(f\"Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d4349b",
   "metadata": {},
   "source": [
    "## 2. Basic Structure Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a37c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column info\n",
    "print(\"Dataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected columns from PRD\n",
    "expected_columns = [\n",
    "    'step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig',\n",
    "    'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud', 'isFlaggedFraud'\n",
    "]\n",
    "\n",
    "available_features = ['step', 'type', 'amount', 'nameOrig', 'nameDest']\n",
    "restricted_features = ['oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "target_labels = ['isFraud', 'isFlaggedFraud']\n",
    "\n",
    "print(\"Column Validation:\")\n",
    "print(f\"Expected columns: {len(expected_columns)}\")\n",
    "print(f\"Actual columns: {len(df.columns)}\")\n",
    "print(f\"\\nMissing columns: {set(expected_columns) - set(df.columns)}\")\n",
    "print(f\"Extra columns: {set(df.columns) - set(expected_columns)}\")\n",
    "print(f\"\\n‚úÖ Available features (can use): {available_features}\")\n",
    "print(f\"‚ùå Restricted features (cannot use): {restricted_features}\")\n",
    "print(f\"üéØ Target labels: {target_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a451460f",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "missing_df[missing_df['Missing Count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe40a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates:,} ({duplicates/len(df)*100:.4f}%)\")\n",
    "\n",
    "# Check for duplicate transactions (may be valid)\n",
    "dup_by_key = df.duplicated(subset=['step', 'type', 'amount', 'nameOrig', 'nameDest']).sum()\n",
    "print(f\"Duplicate by transaction key: {dup_by_key:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e24399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary (Numerical Features):\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ecf593",
   "metadata": {},
   "source": [
    "## 4. Feature Analysis: Available Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step (time dimension)\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP (Time Dimension)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Min step: {df['step'].min()}\")\n",
    "print(f\"Max step: {df['step'].max()}\")\n",
    "print(f\"Unique steps: {df['step'].nunique()}\")\n",
    "print(f\"Range: {df['step'].min()} to {df['step'].max()} (Expected: 1-744)\")\n",
    "print(f\"\\nTransactions per step (hour):\")\n",
    "print(df.groupby('step').size().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe66e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type (transaction type)\n",
    "print(\"=\" * 60)\n",
    "print(\"TYPE (Transaction Type)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Unique types: {df['type'].nunique()}\")\n",
    "print(f\"\\nTransaction type distribution:\")\n",
    "type_dist = df['type'].value_counts().sort_index()\n",
    "type_pct = (type_dist / len(df) * 100).round(2)\n",
    "pd.DataFrame({\n",
    "    'Count': type_dist,\n",
    "    'Percentage': type_pct\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount\n",
    "print(\"=\" * 60)\n",
    "print(\"AMOUNT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Min amount: {df['amount'].min():,.2f}\")\n",
    "print(f\"Max amount: {df['amount'].max():,.2f}\")\n",
    "print(f\"Mean amount: {df['amount'].mean():,.2f}\")\n",
    "print(f\"Median amount: {df['amount'].median():,.2f}\")\n",
    "print(f\"Std amount: {df['amount'].std():,.2f}\")\n",
    "print(f\"\\nZero amounts: {(df['amount'] == 0).sum():,}\")\n",
    "print(f\"Negative amounts: {(df['amount'] < 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nameOrig (sender)\n",
    "print(\"=\" * 60)\n",
    "print(\"nameOrig (Sender/Origin)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Unique originators: {df['nameOrig'].nunique():,}\")\n",
    "print(f\"Total transactions: {len(df):,}\")\n",
    "print(f\"Avg transactions per originator: {len(df) / df['nameOrig'].nunique():.2f}\")\n",
    "print(f\"\\nTop 10 most active originators:\")\n",
    "df['nameOrig'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nameDest (recipient)\n",
    "print(\"=\" * 60)\n",
    "print(\"nameDest (Recipient/Destination)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Unique recipients: {df['nameDest'].nunique():,}\")\n",
    "print(f\"Total transactions: {len(df):,}\")\n",
    "print(f\"Avg transactions per recipient: {len(df) / df['nameDest'].nunique():.2f}\")\n",
    "print(f\"\\nTop 10 most active recipients:\")\n",
    "df['nameDest'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity ID patterns (C = Customer, M = Merchant)\n",
    "print(\"=\" * 60)\n",
    "print(\"Entity ID Patterns\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def analyze_entity_prefix(series, name):\n",
    "    prefixes = series.str[0].value_counts()\n",
    "    print(f\"\\n{name} prefixes:\")\n",
    "    for prefix, count in prefixes.items():\n",
    "        print(f\"  {prefix}: {count:,} ({count/len(series)*100:.2f}%)\")\n",
    "\n",
    "analyze_entity_prefix(df['nameOrig'], 'nameOrig')\n",
    "analyze_entity_prefix(df['nameDest'], 'nameDest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09eaa6d",
   "metadata": {},
   "source": [
    "## 5. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d51e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isFraud distribution\n",
    "print(\"=\" * 60)\n",
    "print(\"isFraud (Target Variable)\")\n",
    "print(\"=\" * 60)\n",
    "fraud_dist = df['isFraud'].value_counts().sort_index()\n",
    "fraud_pct = (fraud_dist / len(df) * 100).round(4)\n",
    "\n",
    "fraud_df = pd.DataFrame({\n",
    "    'Count': fraud_dist,\n",
    "    'Percentage': fraud_pct\n",
    "})\n",
    "fraud_df.index = ['Not Fraud', 'Fraud']\n",
    "print(fraud_df)\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Class Imbalance Ratio: 1:{(fraud_dist[0] / fraud_dist[1]):.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124586f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isFlaggedFraud (high-value transfer rule)\n",
    "print(\"=\" * 60)\n",
    "print(\"isFlaggedFraud (Rule: TRANSFER > 200,000)\")\n",
    "print(\"=\" * 60)\n",
    "flagged_dist = df['isFlaggedFraud'].value_counts().sort_index()\n",
    "flagged_pct = (flagged_dist / len(df) * 100).round(4)\n",
    "\n",
    "flagged_df = pd.DataFrame({\n",
    "    'Count': flagged_dist,\n",
    "    'Percentage': flagged_pct\n",
    "})\n",
    "flagged_df.index = ['Not Flagged', 'Flagged']\n",
    "print(flagged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between isFraud and isFlaggedFraud\n",
    "print(\"=\" * 60)\n",
    "print(\"Confusion Matrix: isFlaggedFraud vs isFraud\")\n",
    "print(\"=\" * 60)\n",
    "confusion = pd.crosstab(\n",
    "    df['isFlaggedFraud'], \n",
    "    df['isFraud'], \n",
    "    rownames=['isFlaggedFraud'], \n",
    "    colnames=['isFraud'],\n",
    "    margins=True\n",
    ")\n",
    "print(confusion)\n",
    "\n",
    "# Check if flagged transactions are actually fraud\n",
    "flagged_txns = df[df['isFlaggedFraud'] == 1]\n",
    "if len(flagged_txns) > 0:\n",
    "    flagged_fraud_rate = flagged_txns['isFraud'].mean() * 100\n",
    "    print(f\"\\nPrecision of isFlaggedFraud rule: {flagged_fraud_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd60ef44",
   "metadata": {},
   "source": [
    "## 6. Fraud Analysis by Transaction Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud by type\n",
    "print(\"=\" * 60)\n",
    "print(\"Fraud Distribution by Transaction Type\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fraud_by_type = df.groupby('type').agg({\n",
    "    'isFraud': ['sum', 'mean', 'count']\n",
    "}).round(4)\n",
    "fraud_by_type.columns = ['Fraud Count', 'Fraud Rate', 'Total Transactions']\n",
    "fraud_by_type['Fraud Rate'] = (fraud_by_type['Fraud Rate'] * 100).round(2)\n",
    "fraud_by_type = fraud_by_type.sort_values('Fraud Rate', ascending=False)\n",
    "print(fraud_by_type)\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Key Insight: Fraud occurs only in specific transaction types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount distribution for fraud vs non-fraud\n",
    "print(\"=\" * 60)\n",
    "print(\"Amount Statistics: Fraud vs Non-Fraud\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "amount_stats = df.groupby('isFraud')['amount'].describe()\n",
    "amount_stats.index = ['Not Fraud', 'Fraud']\n",
    "print(amount_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5add4ae",
   "metadata": {},
   "source": [
    "## 7. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction type distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Count\n",
    "df['type'].value_counts().plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Transaction Type Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Transaction Type')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Percentage\n",
    "(df['type'].value_counts() / len(df) * 100).plot(kind='bar', ax=axes[1], color='coral')\n",
    "axes[1].set_title('Transaction Type Distribution (%)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Transaction Type')\n",
    "axes[1].set_ylabel('Percentage')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52458668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Class imbalance\n",
    "fraud_counts = df['isFraud'].value_counts()\n",
    "axes[0].pie(fraud_counts, labels=['Not Fraud', 'Fraud'], autopct='%1.2f%%', colors=['lightgreen', 'red'])\n",
    "axes[0].set_title('Class Distribution: isFraud', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Fraud by transaction type\n",
    "fraud_by_type_plot = df.groupby('type')['isFraud'].mean() * 100\n",
    "fraud_by_type_plot.plot(kind='bar', ax=axes[1], color='indianred')\n",
    "axes[1].set_title('Fraud Rate by Transaction Type', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Transaction Type')\n",
    "axes[1].set_ylabel('Fraud Rate (%)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].axhline(y=df['isFraud'].mean() * 100, color='black', linestyle='--', label='Overall Rate')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c7729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount distribution (log scale)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Non-fraud\n",
    "non_fraud = df[df['isFraud'] == 0]['amount']\n",
    "axes[0].hist(np.log10(non_fraud[non_fraud > 0]), bins=50, color='lightblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Amount Distribution: Not Fraud (log10 scale)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('log10(Amount)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Fraud\n",
    "fraud = df[df['isFraud'] == 1]['amount']\n",
    "axes[1].hist(np.log10(fraud[fraud > 0]), bins=50, color='salmon', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Amount Distribution: Fraud (log10 scale)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('log10(Amount)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions over time (steps)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# All transactions\n",
    "step_counts = df.groupby('step').size()\n",
    "axes[0].plot(step_counts.index, step_counts.values, color='steelblue', linewidth=1)\n",
    "axes[0].set_title('Transaction Volume Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Step (Hour)')\n",
    "axes[0].set_ylabel('Transaction Count')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Fraud transactions\n",
    "fraud_by_step = df[df['isFraud'] == 1].groupby('step').size()\n",
    "axes[1].plot(fraud_by_step.index, fraud_by_step.values, color='red', linewidth=1)\n",
    "axes[1].set_title('Fraud Transaction Volume Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Step (Hour)')\n",
    "axes[1].set_ylabel('Fraud Count')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8b986d",
   "metadata": {},
   "source": [
    "## 8. Data Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATA VALIDATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "validations = [\n",
    "    (\"‚úÖ\", \"All expected columns present\", set(expected_columns) == set(df.columns)),\n",
    "    (\"‚úÖ\", \"No missing values\", df.isnull().sum().sum() == 0),\n",
    "    (\"‚úÖ\", \"Step range valid (1-744)\", df['step'].min() == 1 and df['step'].max() == 744),\n",
    "    (\"‚úÖ\", \"Transaction types valid\", df['type'].nunique() == 5),\n",
    "    (\"‚úÖ\", \"No negative amounts\", (df['amount'] < 0).sum() == 0),\n",
    "    (\"‚úÖ\", \"High cardinality entities\", df['nameOrig'].nunique() > 1000 and df['nameDest'].nunique() > 1000),\n",
    "    (\"‚ö†Ô∏è\", \"Severe class imbalance\", (df['isFraud'].sum() / len(df)) < 0.01),\n",
    "    (\"‚úÖ\", \"Fraud only in specific types\", df.groupby('type')['isFraud'].sum().gt(0).sum() <= 3),\n",
    "]\n",
    "\n",
    "for symbol, description, condition in validations:\n",
    "    print(f\"{symbol} {description}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üìä Dataset Size: {len(df):,} transactions\")\n",
    "print(f\"üìÖ Time Range: {df['step'].nunique()} steps (hours)\")\n",
    "print(f\"üë• Unique Originators: {df['nameOrig'].nunique():,}\")\n",
    "print(f\"üè™ Unique Recipients: {df['nameDest'].nunique():,}\")\n",
    "print(f\"üí∞ Amount Range: {df['amount'].min():,.2f} to {df['amount'].max():,.2f}\")\n",
    "print(f\"üö® Fraud Rate: {df['isFraud'].mean() * 100:.4f}%\")\n",
    "print(f\"‚öñÔ∏è Class Imbalance: 1:{(df['isFraud'].value_counts()[0] / df['isFraud'].value_counts()[1]):.0f}\")\n",
    "\n",
    "fraud_types = df[df['isFraud'] == 1]['type'].unique()\n",
    "print(f\"üéØ Fraud occurs in: {', '.join(fraud_types)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"1. ‚úÖ Dataset structure validated\")\n",
    "print(\"2. üîÑ Design feature engineering strategy (behavioral features only)\")\n",
    "print(\"3. üîÑ Implement time-based train/val/test split\")\n",
    "print(\"4. üîÑ Handle class imbalance (sampling, weights, metrics)\")\n",
    "print(\"5. üîÑ Baseline model development\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
